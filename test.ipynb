{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xshang/miniconda3/envs/llamaEnv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix,\n",
    "                             f1_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get working directory\n",
    "cwd = os.getcwd()\n",
    "data_dir = os.path.join(cwd, 'data')\n",
    "model_dir = os.path.join(cwd, 'model')\n",
    "\n",
    "# load data and pre-process datasets\n",
    "train_df = pd.read_csv(os.path.join(data_dir, 'gptTrainNames.csv'))\n",
    "test_df = pd.read_csv(os.path.join(data_dir, 'gptTestNames.csv'))\n",
    "val_df = pd.read_csv(os.path.join(data_dir, 'gptValNames.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = list()\n",
    "# X_test = list()\n",
    "# for race in [\"API\", \"White\", \"Black\", \"Hispanic\"]:\n",
    "#     train, test  = train_test_split(train_df[train_df.label==race], \n",
    "#                                     train_size=300,\n",
    "#                                     test_size=300, \n",
    "#                                     random_state=42)\n",
    "#     X_train.append(train)\n",
    "#     X_test.append(test)\n",
    "\n",
    "# X_train, X_eval  = train_test_split(train_df, \n",
    "#                                 train_size=int(len(train_df) * 0.008),\n",
    "#                                 test_size=int(len(train_df) * 0.002), \n",
    "#                                 random_state=42)\n",
    "\n",
    "# X_train = pd.concat(X_train).sample(frac=1, random_state=10)\n",
    "# X_test = pd.concat(X_test)\n",
    "\n",
    "# eval_idx = [idx for idx in train_df.index if idx not in list(train.index) + list(test.index)]\n",
    "# X_eval = train_df[train_df.index.isin(eval_idx)]\n",
    "# X_train, X_eval = train_test_split(X_train, \n",
    "#                                 test_size=0.1,\n",
    "#                                 random_state=42)\n",
    "# X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "\n",
    "X_train = train_df.sample(frac=0.01, random_state=10)\n",
    "X_test = test_df.sample(frac=0.01, random_state=10)\n",
    "X_eval = val_df.sample(frac=0.01, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93395, 25943, 10377)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "def generate_prompt(data_point, shuffle=False):\n",
    "    if not shuffle:\n",
    "        return f\"\"\"\n",
    "                Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: Asian, Black, Hispanic, or White. \n",
    "                Your answer should only be the category name.\n",
    "                [{data_point[\"name\"]}].\n",
    "                ANSWER: {data_point[\"label\"]}\n",
    "                \"\"\".strip()\n",
    "    \n",
    "    categories = [\"Hispanic\", \"Black\", \"White\", \"Asian\"]\n",
    "    random.shuffle(categories)\n",
    "    categories_str = ', '.join(categories)\n",
    "    return f\"\"\"\n",
    "            Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: {categories_str}. \n",
    "            Your answer should only be the category name.\n",
    "            [{data_point[\"name\"]}]\n",
    "            ANSWER: {data_point[\"label\"]}\n",
    "            \"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point, shuffle=False):\n",
    "    if not shuffle:\n",
    "        return f\"\"\"\n",
    "                Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: Asian, Black, Hispanic, or White. \n",
    "                Your answer should only be the category name.\n",
    "                [{data_point[\"name\"]}]\n",
    "                ANSWER: \"\"\".strip()\n",
    "    \n",
    "    categories = [\"Hispanic\", \"Black\", \"White\", \"Asian\"]\n",
    "    random.shuffle(categories)\n",
    "    categories_str = ', '.join(categories)\n",
    "    return f\"\"\"\n",
    "            Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: {categories_str}. \n",
    "            Your answer should only be the category name.\n",
    "            [{data_point[\"name\"]}]\n",
    "            ANSWER: \"\"\".strip()\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train.apply(lambda row: generate_prompt(row, shuffle=False), axis=1), \n",
    "                       columns=[\"name\"])\n",
    "X_eval = pd.DataFrame(X_eval.apply(lambda row: generate_prompt(row, shuffle=False), axis=1), \n",
    "                       columns=[\"name\"])\n",
    "\n",
    "y_true = X_test.label.values\n",
    "print(type(y_true))\n",
    "X_test_1 = pd.DataFrame(X_test.apply(lambda row: generate_test_prompt(row, shuffle=True), axis=1), \n",
    "                      columns=[\"name\"])\n",
    "X_test_2 = pd.DataFrame(X_test.apply(lambda row: generate_test_prompt(row, shuffle=False), axis=1), \n",
    "                      columns=[\"name\"])\n",
    "\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "eval_data = Dataset.from_pandas(X_eval)\n",
    "\n",
    "del train_df, test_df, val_df, X_train, X_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black\n"
     ]
    }
   ],
   "source": [
    "print(y_true[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels = ['API', 'Black', 'Hispanic', 'White']\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred, target_names=labels)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=labels)\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.31s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=compute_dtype,\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "                                          trust_remote_code=True,\n",
    "                                         )\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(test))):\n",
    "    # for i in [69, 222, 676, 1270, 2060, 3684, 3827, 4472, 4799, 4972, 5120]:\n",
    "        prompt = test.iloc[i][\"name\"]\n",
    "        pipe = pipeline(task=\"text-generation\", \n",
    "                        model=model, \n",
    "                        tokenizer=tokenizer, \n",
    "                        max_new_tokens = 4, \n",
    "                        # temperature = 0.01,\n",
    "                        do_sample = False,\n",
    "                       )\n",
    "        result = pipe(prompt)\n",
    "        answer = result[0]['generated_text'].split(\":\")[-1].lower()\n",
    "        # print(prompt, answer)\n",
    "        if \"asian\" in answer:\n",
    "            y_pred.append(\"API\")\n",
    "        elif \"black\" in answer:\n",
    "            y_pred.append(\"Black\")\n",
    "        elif \"hispanic\" in answer:\n",
    "            y_pred.append(\"Hispanic\")\n",
    "        elif \"white\" in answer:\n",
    "            y_pred.append(\"White\")\n",
    "        else:\n",
    "            y_pred.append(\"none\")\n",
    "            print(prompt,answer)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/518 [00:00<?, ?it/s]/WAVE/projects/newsq_scu/xiaoxiao_git/Llama-race/venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/WAVE/projects/newsq_scu/xiaoxiao_git/Llama-race/venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 518/518 [07:09<00:00,  1.21it/s]\n",
      "100%|██████████| 518/518 [07:10<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test_1, model, tokenizer)\n",
    "y_pred1 = predict(X_test_2, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_res = set(y_pred)  # Get unique labels\n",
    "print(unique_res)\n",
    "\n",
    "unique_labels = set(y_true)\n",
    "print(unique_labels)\n",
    "\n",
    "labels = list(set(list(set(y_true))+list(set(y_pred))))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.463\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         API       0.07      0.55      0.13        11\n",
      "       Black       0.20      0.46      0.28        80\n",
      "    Hispanic       0.75      0.73      0.74        92\n",
      "       White       0.80      0.39      0.52       335\n",
      "\n",
      "    accuracy                           0.46       518\n",
      "   macro avg       0.46      0.53      0.42       518\n",
      "weighted avg       0.68      0.46      0.52       518\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  6   4   1   0]\n",
      " [ 14  37   5  24]\n",
      " [  4  13  67   8]\n",
      " [ 56 133  16 130]]\n",
      "Accuracy: 0.320\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         API       0.04      1.00      0.07        11\n",
      "       Black       0.37      0.31      0.34        80\n",
      "    Hispanic       0.93      0.72      0.81        92\n",
      "       White       0.88      0.19      0.31       335\n",
      "\n",
      "    accuracy                           0.32       518\n",
      "   macro avg       0.55      0.56      0.38       518\n",
      "weighted avg       0.79      0.32      0.40       518\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 11   0   0   0]\n",
      " [ 45  25   2   8]\n",
      " [ 25   0  66   1]\n",
      " [226  42   3  64]]\n"
     ]
    }
   ],
   "source": [
    "# y_pred = ['API' if 'Asia Pacific Islander' in x else x for x in y_pred]\n",
    "evaluate(y_true, y_pred)\n",
    "evaluate(y_true, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Micro): 0.463\n",
      "F1 Score (Macro): 0.418\n",
      "F1 Score (Weighted): 0.515\n",
      "--------------below is for shuffle test----------------\n",
      "F1 Score (Micro): 0.320\n",
      "F1 Score (Macro): 0.383\n",
      "F1 Score (Weighted): 0.401\n"
     ]
    }
   ],
   "source": [
    "f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f\"F1 Score (Micro): {f1_micro:.3f}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.3f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted:.3f}\")\n",
    "\n",
    "print(\"--------------below is for un-shuffle test----------------\")\n",
    "f1_micro = f1_score(y_true, y_pred1, average='micro')\n",
    "f1_macro = f1_score(y_true, y_pred1, average='macro')\n",
    "f1_weighted = f1_score(y_true, y_pred1, average='weighted')\n",
    "print(f\"F1 Score (Micro): {f1_micro:.3f}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.3f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: Hispanic, White, Asian, Black. \n",
      "            Your answer should only be the category name.\n",
      "            [Rodriguez Ana]\n",
      "            ANSWER:\n",
      "Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: Asian, Black, Hispanic, or White. \n",
      "                Your answer should only be the category name.\n",
      "                [Rodriguez Ana]\n",
      "                ANSWER:\n",
      "Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: Asian, Black, Hispanic, or White. \n",
      "                Your answer should only be the category name.\n",
      "                [Janicki Robert].\n",
      "                ANSWER: White\n"
     ]
    }
   ],
   "source": [
    "print(X_test_1.iloc[0][\"name\"])\n",
    "print(X_test_2.iloc[0][\"name\"])\n",
    "print(train_data[0]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 93395/93395 [00:15<00:00, 5966.01 examples/s]\n",
      "Map: 100%|██████████| 10377/10377 [00:01<00:00, 5892.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "output_dir=\"trained_weigths\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=16, \n",
    "        lora_dropout=0.1,\n",
    "        r=64,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,                    # directory to save and repository id\n",
    "    num_train_epochs=2,                       # number of training epochs\n",
    "    per_device_train_batch_size=128,            # batch size per device during training\n",
    "    gradient_accumulation_steps=1,            # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=25,                         # log every 10 steps\n",
    "    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n",
    "    report_to=\"tensorboard\",                  # report metrics to tensorboard\n",
    "    evaluation_strategy=\"epoch\"               # save checkpoint every epoch\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"name\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=None,\n",
    "    packing=False,\n",
    "    dataset_batch_size=32,\n",
    "    # dataset_kwargs={\n",
    "    #     \"add_special_tokens\": False,\n",
    "    #     \"append_concat_token\": False,\n",
    "    # }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='1460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   8/1460 01:54 < 7:40:27, 0.05 it/s, Epoch 0.01/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llamaEnv/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:323\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 323\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m~/miniconda3/envs/llamaEnv/lib/python3.11/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llamaEnv/lib/python3.11/site-packages/transformers/trainer.py:1869\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1875\u001b[0m ):\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/llamaEnv/lib/python3.11/site-packages/transformers/trainer.py:2781\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2779\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2780\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2781\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/miniconda3/envs/llamaEnv/lib/python3.11/site-packages/accelerate/accelerator.py:1964\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1962\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1964\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llamaEnv/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llamaEnv/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(output_dir)\n",
    "trainer.tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/518 [00:00<?, ?it/s]/WAVE/projects/newsq_scu/xiaoxiao_git/Llama-race/venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/WAVE/projects/newsq_scu/xiaoxiao_git/Llama-race/venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "  7%|▋         | 38/518 [00:29<06:13,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: Asian, Hispanic, White, Black. \n",
      "            Your answer should only be the category name.\n",
      "            [Vongrasamy Phouphet]\n",
      "            ANSWER:  apia\n",
      "           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 46/518 [00:35<06:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: Asian, White, Hispanic, Black. \n",
      "            Your answer should only be the category name.\n",
      "            [Nguyen Nhuy]\n",
      "            ANSWER:  apia\n",
      "           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 348/518 [04:30<02:11,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: Hispanic, Asian, Black, White. \n",
      "            Your answer should only be the category name.\n",
      "            [Lu Libo]\n",
      "            ANSWER:  apia\n",
      "           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 405/518 [05:14<01:27,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: Asian, White, Black, Hispanic. \n",
      "            Your answer should only be the category name.\n",
      "            [Tufts Mikyong]\n",
      "            ANSWER:  apia\n",
      "           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 518/518 [06:42<00:00,  1.29it/s]\n",
      "  7%|▋         | 38/518 [00:29<06:12,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: Asian, Black, Hispanic, or White. \n",
      "                Your answer should only be the category name.\n",
      "                [Vongrasamy Phouphet]\n",
      "                ANSWER:  apia\n",
      "           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 46/518 [00:35<06:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: Asian, Black, Hispanic, or White. \n",
      "                Your answer should only be the category name.\n",
      "                [Nguyen Nhuy]\n",
      "                ANSWER:  api\n",
      "            }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 348/518 [04:30<02:11,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: Asian, Black, Hispanic, or White. \n",
      "                Your answer should only be the category name.\n",
      "                [Lu Libo]\n",
      "                ANSWER:  apia\n",
      "           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 405/518 [05:14<01:27,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: Asian, Black, Hispanic, or White. \n",
      "                Your answer should only be the category name.\n",
      "                [Tufts Mikyong]\n",
      "                ANSWER:  apia\n",
      "           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 461/518 [05:58<00:44,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess the race of the name enclosed in square brackets into 1 of the following 4 categories: Asian, Black, Hispanic, or White. \n",
      "                Your answer should only be the category name.\n",
      "                [Nagassar Sharmila]\n",
      "                ANSWER:  api\n",
      "            </\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 518/518 [06:42<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = predict(X_test_1, model, tokenizer)\n",
    "y_pred1 = predict(X_test_2, model, tokenizer)\n",
    "# evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.811\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         API       1.00      0.45      0.62        11\n",
      "       Black       0.67      0.17      0.28        80\n",
      "    Hispanic       0.90      0.84      0.87        92\n",
      "       White       0.80      0.97      0.87       335\n",
      "\n",
      "    accuracy                           0.81       518\n",
      "   macro avg       0.84      0.61      0.66       518\n",
      "weighted avg       0.80      0.81      0.78       518\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  5   0   1   5]\n",
      " [  0  14   4  62]\n",
      " [  0   0  77  15]\n",
      " [  0   7   4 324]]\n",
      "Accuracy: 0.817\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         API       1.00      0.55      0.71        11\n",
      "       Black       0.59      0.21      0.31        80\n",
      "    Hispanic       0.90      0.86      0.88        92\n",
      "       White       0.81      0.96      0.88       335\n",
      "\n",
      "    accuracy                           0.82       518\n",
      "   macro avg       0.82      0.64      0.69       518\n",
      "weighted avg       0.80      0.82      0.79       518\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  6   0   1   4]\n",
      " [  0  17   5  58]\n",
      " [  0   1  79  12]\n",
      " [  0  11   3 321]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ['API' if 'none' in x else x for x in y_pred]\n",
    "y_pred1 = ['API' if 'none' in x else x for x in y_pred1]\n",
    "evaluate(y_true, y_pred)\n",
    "evaluate(y_true, y_pred1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Micro): 0.811\n",
      "F1 Score (Macro): 0.660\n",
      "F1 Score (Weighted): 0.775\n",
      "--------------below is for shuffle test----------------\n",
      "F1 Score (Micro): 0.817\n",
      "F1 Score (Macro): 0.694\n",
      "F1 Score (Weighted): 0.788\n"
     ]
    }
   ],
   "source": [
    "f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f\"F1 Score (Micro): {f1_micro:.3f}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.3f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted:.3f}\")\n",
    "print(\"--------------below is for shuffle test----------------\")\n",
    "f1_micro = f1_score(y_true, y_pred1, average='micro')\n",
    "f1_macro = f1_score(y_true, y_pred1, average='macro')\n",
    "f1_weighted = f1_score(y_true, y_pred1, average='weighted')\n",
    "print(f\"F1 Score (Micro): {f1_micro:.3f}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.3f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=['API','Black','Hispanic','White'])\n",
    "metrics_per_class = {}\n",
    "tpr, tnr = [], []\n",
    "for i in range(len(cm)):\n",
    "    TP = cm[i, i]\n",
    "    FP = sum(cm[:, i]) - TP\n",
    "    FN = sum(cm[i, :]) - TP\n",
    "    TN = sum(cm.sum(axis=1)) - TP - FP - FN\n",
    "    TPR = TP / float(TP + FN) if (TP + FN) > 0 else 0\n",
    "    TNR = TN / float(TN + FP) if (TN + FP) > 0 else 0\n",
    "    # class_label = le.inverse_transform([i])[0]  # Convert index back to original class label\n",
    "    # metrics_per_class[class_label] = {'TPR': TPR, 'TNR': TNR}\n",
    "    tpr.append(TPR)\n",
    "    tnr.append(TNR)\n",
    "\n",
    "temp = (np.array(tpr)+np.array(tnr))*0.5\n",
    "# print(temp)\n",
    "gap = 0.0\n",
    "for i in range(len(temp)-1):\n",
    "    gap += abs(temp[i]-temp[-1])\n",
    "gap /= 3\n",
    "print('1-GAP is:',1-gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = [0.09, 0.97, 0.4, 0.02]\n",
    "\n",
    "dis = 0.0\n",
    "for i in range(len(recalls)-1):\n",
    "    dis += recalls[i]/recalls[-1]\n",
    "dis /= (len(recalls)-1)\n",
    "print('Disparate Impact is:',dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
