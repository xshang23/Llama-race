{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/WAVE/projects/newsq_scu/xiaoxiao_git/Llama-race/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix,\n",
    "                             f1_score)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version 2.2.0+cu121\n"
     ]
    }
   ],
   "source": [
    "print(f\"pytorch version {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get working directory\n",
    "cwd = os.getcwd()\n",
    "data_dir = os.path.join(cwd, 'data')\n",
    "model_dir = os.path.join(cwd, 'model')\n",
    "\n",
    "# load data and pre-process datasets\n",
    "train_df = pd.read_csv(os.path.join(data_dir, 'gptTestNames.csv'))\n",
    "# test_df = pd.read_csv(os.path.join(data_dir, 'gptTestNames.csv'))\n",
    "# val_df = pd.read_csv(os.path.join(data_dir, 'gptValNames.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = list()\n",
    "# X_test = list()\n",
    "# for race in [\"API\", \"White\", \"Black\", \"Hispanic\"]:\n",
    "#     train, test  = train_test_split(train_df[train_df.label==race], \n",
    "#                                     train_size=300,\n",
    "#                                     test_size=300, \n",
    "#                                     random_state=42)\n",
    "#     X_train.append(train)\n",
    "#     X_test.append(test)\n",
    "\n",
    "X_train, X_test  = train_test_split(train_df, \n",
    "                                train_size=int(len(train_df) * 0.008),\n",
    "                                test_size=int(len(train_df) * 0.002), \n",
    "                                random_state=42)\n",
    "\n",
    "# X_train = pd.concat(X_train).sample(frac=1, random_state=10)\n",
    "# X_test = pd.concat(X_test)\n",
    "\n",
    "# eval_idx = [idx for idx in train_df.index if idx not in list(train.index) + list(test.index)]\n",
    "# X_eval = train_df[train_df.index.isin(eval_idx)]\n",
    "X_train, X_eval = train_test_split(X_train, \n",
    "                                test_size=0.1,\n",
    "                                random_state=42)\n",
    "X_train = X_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18678, 5188, 2076)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Category the name enclosed in square brackets, \n",
    "            into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White.\n",
    "            Your answer should only be the category name. \n",
    "            [{data_point[\"name\"]}].\n",
    "            ANSWER: {data_point[\"label\"]}\n",
    "            \"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Category the name enclosed in square brackets, \n",
    "            into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White.\n",
    "            Your answer should only be the category name.\n",
    "            [{data_point[\"name\"]}]\n",
    "            ANSWER: \"\"\".strip()\n",
    "\n",
    "X_train = pd.DataFrame(X_train.apply(generate_prompt, axis=1), \n",
    "                       columns=[\"name\"])\n",
    "X_eval = pd.DataFrame(X_eval.apply(generate_prompt, axis=1), \n",
    "                      columns=[\"name\"])\n",
    "\n",
    "y_true = X_test.label\n",
    "X_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"name\"])\n",
    "\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "eval_data = Dataset.from_pandas(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels = ['API', 'Black', 'Hispanic', 'White','none']\n",
    "    mapping = {'API': 0, 'Black': 1, 'Hispanic':2, 'White': 3, 'none': 4}\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "    \n",
    "    y_true = np.vectorize(map_func)(y_true)\n",
    "    y_pred = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true)) \n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred, target_names=labels)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=labels)\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.47s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=compute_dtype,\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "                                          trust_remote_code=True,\n",
    "                                         )\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(test))):\n",
    "    # for i in [69, 222, 676, 1270, 2060, 3684, 3827, 4472, 4799, 4972, 5120]:\n",
    "        prompt = test.iloc[i][\"name\"]\n",
    "        pipe = pipeline(task=\"text-generation\", \n",
    "                        model=model, \n",
    "                        tokenizer=tokenizer, \n",
    "                        max_new_tokens = 4, \n",
    "                        # temperature = 0.0,\n",
    "                        do_sample = False,\n",
    "                       )\n",
    "        result = pipe(prompt)\n",
    "        answer = result[0]['generated_text'].split(\":\")[-1]\n",
    "        if \"Pacific Islander\" in answer:\n",
    "            y_pred.append(\"API\")\n",
    "        elif \"Black\" in answer:\n",
    "            y_pred.append(\"Black\")\n",
    "        elif \"Hispanic\" in answer:\n",
    "            y_pred.append(\"Hispanic\")\n",
    "        elif \"White\" in answer:\n",
    "            y_pred.append(\"White\")\n",
    "        else:\n",
    "            y_pred.append(\"none\")\n",
    "            print(prompt,answer)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/WAVE/projects/newsq_scu/xiaoxiao_git/Llama-race/venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/WAVE/projects/newsq_scu/xiaoxiao_git/Llama-race/venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category the name enclosed in square brackets, \n",
      "            into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White.\n",
      "            Your answer should only be the category name.\n",
      "            [Houston Jennifer]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets, \n",
      "            into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White.\n",
      "            Your answer should only be the category name.\n",
      "            [Coma Allter]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets, \n",
      "            into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White.\n",
      "            Your answer should only be the category name.\n",
      "            [Showers Mark]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets, \n",
      "            into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White.\n",
      "            Your answer should only be the category name.\n",
      "            [Cubas Jhon]\n",
      "            ANSWER:  Hispanic\n",
      "\n",
      "Category the name enclosed in square brackets, \n",
      "            into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White.\n",
      "            Your answer should only be the category name.\n",
      "            [Honer Barbara]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets, \n",
      "            into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White.\n",
      "            Your answer should only be the category name.\n",
      "            [Toler Passion]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets, \n",
      "            into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White.\n",
      "            Your answer should only be the category name.\n",
      "            [Malek John]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets, \n",
      "            into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White.\n",
      "            Your answer should only be the category name.\n",
      "            [Stack Mark]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets, \n",
      "            into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White.\n",
      "            Your answer should only be the category name.\n",
      "            [Toth Tibor]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets, \n",
      "            into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White.\n",
      "            Your answer should only be the category name.\n",
      "            [Husbands Diane]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets, \n",
      "            into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White.\n",
      "            Your answer should only be the category name.\n",
      "            [Johnson Africa]\n",
      "            ANSWER:  Black\n",
      "\n",
      "       \n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hispanic', 'White', 'API', 'Black', 'none'}\n",
      "{'Black', 'Hispanic', 'White', 'API'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hispanic', 'White', 'API', 'Black', 'none']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_res = set(y_pred)  # Get unique labels\n",
    "print(unique_res)\n",
    "\n",
    "unique_labels = set(y_true)\n",
    "print(unique_labels)\n",
    "\n",
    "labels = list(set(list(set(y_true))+list(set(y_pred))))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[69, 222, 676, 1270, 2060, 3684, 3827, 4472, 4799, 4972, 5120]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [i for i, x in enumerate(y_pred) if x == \"none\"]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Category the name enclosed in square brackets, \\n            into 4 categories: Asia Pacific Islander, Black, Hispanic, or White.\\n\\n            [Houston Jennifer] ='\n",
      " 'Category the name enclosed in square brackets, \\n            into 4 categories: Asia Pacific Islander, Black, Hispanic, or White.\\n\\n            [Coma Allter] ='\n",
      " 'Category the name enclosed in square brackets, \\n            into 4 categories: Asia Pacific Islander, Black, Hispanic, or White.\\n\\n            [Showers Mark] ='\n",
      " 'Category the name enclosed in square brackets, \\n            into 4 categories: Asia Pacific Islander, Black, Hispanic, or White.\\n\\n            [Cubas Jhon] ='\n",
      " 'Category the name enclosed in square brackets, \\n            into 4 categories: Asia Pacific Islander, Black, Hispanic, or White.\\n\\n            [Honer Barbara] ='\n",
      " 'Category the name enclosed in square brackets, \\n            into 4 categories: Asia Pacific Islander, Black, Hispanic, or White.\\n\\n            [Toler Passion] ='\n",
      " 'Category the name enclosed in square brackets, \\n            into 4 categories: Asia Pacific Islander, Black, Hispanic, or White.\\n\\n            [Malek John] ='\n",
      " 'Category the name enclosed in square brackets, \\n            into 4 categories: Asia Pacific Islander, Black, Hispanic, or White.\\n\\n            [Stack Mark] ='\n",
      " 'Category the name enclosed in square brackets, \\n            into 4 categories: Asia Pacific Islander, Black, Hispanic, or White.\\n\\n            [Toth Tibor] ='\n",
      " 'Category the name enclosed in square brackets, \\n            into 4 categories: Asia Pacific Islander, Black, Hispanic, or White.\\n\\n            [Husbands Diane] ='\n",
      " 'Category the name enclosed in square brackets, \\n            into 4 categories: Asia Pacific Islander, Black, Hispanic, or White.\\n\\n            [Johnson Africa] =']\n"
     ]
    }
   ],
   "source": [
    "print(X_test.iloc[indices].name.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.418\n",
      "Accuracy for label 0: 0.894\n",
      "Accuracy for label 1: 0.042\n",
      "Accuracy for label 2: 0.421\n",
      "Accuracy for label 3: 0.478\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         API       0.03      0.89      0.07       104\n",
      "       Black       0.49      0.04      0.08       706\n",
      "    Hispanic       0.85      0.42      0.56       874\n",
      "       White       0.85      0.48      0.61      3504\n",
      "        none       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.42      5188\n",
      "   macro avg       0.45      0.37      0.26      5188\n",
      "weighted avg       0.79      0.42      0.52      5188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/WAVE/projects/newsq_scu/xiaoxiao_git/Llama-race/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/WAVE/projects/newsq_scu/xiaoxiao_git/Llama-race/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/WAVE/projects/newsq_scu/xiaoxiao_git/Llama-race/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least one label specified must be in y_true",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# y_pred = ['API' if 'Asia Pacific Islander' in x else x for x in y_pred]\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 31\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(class_report)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Generate confusion matrix\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(conf_matrix)\n",
      "File \u001b[0;32m/WAVE/projects/newsq_scu/xiaoxiao_git/Llama-race/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/WAVE/projects/newsq_scu/xiaoxiao_git/Llama-race/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:333\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros((n_labels, n_labels), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39mintersect1d(y_true, labels)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 333\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one label specified must be in y_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n",
      "\u001b[0;31mValueError\u001b[0m: At least one label specified must be in y_true"
     ]
    }
   ],
   "source": [
    "# y_pred = ['API' if 'Asia Pacific Islander' in x else x for x in y_pred]\n",
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 368   59  440    6    1]\n",
      " [  55 1676 1742   25    6]\n",
      " [   4    7   93    0    0]\n",
      " [   5  229  438   30    4]\n",
      " [   0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Micro): 0.418\n",
      "F1 Score (Macro): 0.264\n",
      "F1 Score (Weighted): 0.520\n"
     ]
    }
   ],
   "source": [
    "f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f\"F1 Score (Micro): {f1_micro:.3f}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.3f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
