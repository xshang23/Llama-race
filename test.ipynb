{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/WAVE/projects/newsq_scu/xiaoxiao_git/Llama-race/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix,\n",
    "                             f1_score)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version 2.2.0+cu121\n"
     ]
    }
   ],
   "source": [
    "print(f\"pytorch version {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get working directory\n",
    "cwd = os.getcwd()\n",
    "data_dir = os.path.join(cwd, 'data')\n",
    "model_dir = os.path.join(cwd, 'model')\n",
    "\n",
    "# load data and pre-process datasets\n",
    "train_df = pd.read_csv(os.path.join(data_dir, 'gptTestNames.csv'))\n",
    "# test_df = pd.read_csv(os.path.join(data_dir, 'gptTestNames.csv'))\n",
    "# val_df = pd.read_csv(os.path.join(data_dir, 'gptValNames.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = list()\n",
    "# X_test = list()\n",
    "# for race in [\"API\", \"White\", \"Black\", \"Hispanic\"]:\n",
    "#     train, test  = train_test_split(train_df[train_df.label==race], \n",
    "#                                     train_size=300,\n",
    "#                                     test_size=300, \n",
    "#                                     random_state=42)\n",
    "#     X_train.append(train)\n",
    "#     X_test.append(test)\n",
    "\n",
    "X_train, X_test  = train_test_split(train_df, \n",
    "                                train_size=int(len(train_df) * 0.008),\n",
    "                                test_size=int(len(train_df) * 0.002), \n",
    "                                random_state=42)\n",
    "\n",
    "# X_train = pd.concat(X_train).sample(frac=1, random_state=10)\n",
    "# X_test = pd.concat(X_test)\n",
    "\n",
    "# eval_idx = [idx for idx in train_df.index if idx not in list(train.index) + list(test.index)]\n",
    "# X_eval = train_df[train_df.index.isin(eval_idx)]\n",
    "X_train, X_eval = train_test_split(X_train, \n",
    "                                test_size=0.1,\n",
    "                                random_state=42)\n",
    "X_train = X_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18678, 5188, 2076)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
    "            Your answer should only be the category name. \n",
    "            [{data_point[\"name\"]}].\n",
    "            ANSWER: {data_point[\"label\"]}\n",
    "            \"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
    "            Your answer should only be the category name.\n",
    "            [{data_point[\"name\"]}]\n",
    "            ANSWER: \"\"\".strip()\n",
    "\n",
    "X_train = pd.DataFrame(X_train.apply(generate_prompt, axis=1), \n",
    "                       columns=[\"name\"])\n",
    "X_eval = pd.DataFrame(X_eval.apply(generate_prompt, axis=1), \n",
    "                      columns=[\"name\"])\n",
    "\n",
    "y_true = X_test.label\n",
    "X_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"name\"])\n",
    "\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "eval_data = Dataset.from_pandas(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels = ['API', 'Black', 'Hispanic', 'White']\n",
    "    mapping = {'API': 0, 'Black': 1, 'Hispanic':2, 'White': 3}\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "    \n",
    "    y_true = np.vectorize(map_func)(y_true)\n",
    "    y_pred = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true)) \n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred, target_names=labels)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred)#, labels=labels)\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.49s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=compute_dtype,\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "                                          trust_remote_code=True,\n",
    "                                         )\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(test))):\n",
    "    # for i in [69, 222, 676, 1270, 2060, 3684, 3827, 4472, 4799, 4972, 5120]:\n",
    "        prompt = test.iloc[i][\"name\"]\n",
    "        pipe = pipeline(task=\"text-generation\", \n",
    "                        model=model, \n",
    "                        tokenizer=tokenizer, \n",
    "                        max_new_tokens = 4, \n",
    "                        temperature = 1.0,\n",
    "                        # do_sample = True,\n",
    "                       )\n",
    "        result = pipe(prompt)\n",
    "        answer = result[0]['generated_text'].split(\":\")[-1]\n",
    "        print(prompt, answer)\n",
    "        if \"Pacific Islander\" in answer:\n",
    "            y_pred.append(\"API\")\n",
    "        elif \"Black\" in answer:\n",
    "            y_pred.append(\"Black\")\n",
    "        elif \"Hispanic\" in answer:\n",
    "            y_pred.append(\"Hispanic\")\n",
    "        elif \"White\" in answer:\n",
    "            y_pred.append(\"White\")\n",
    "        else:\n",
    "            y_pred.append(\"none\")\n",
    "            print(prompt,answer)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Houston Jennifer]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Coma Allter]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Showers Mark]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Cubas Jhon]\n",
      "            ANSWER:  Hispanic\n",
      "\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Honer Barbara]\n",
      "            ANSWER:  Black\n",
      "\n",
      "       \n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Toler Passion]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Malek John]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Stack Mark]\n",
      "            ANSWER:  White\n",
      "```\n",
      "\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Toth Tibor]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Husbands Diane]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Johnson Africa]\n",
      "            ANSWER:  Black\n",
      "\n",
      "\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Houston Jennifer]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Coma Allter]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Showers Mark]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Cubas Jhon]\n",
      "            ANSWER:  Hispanic\n",
      "\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Honer Barbara]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Toler Passion]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Malek John]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Stack Mark]\n",
      "            ANSWER:  White\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Toth Tibor]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Husbands Diane]\n",
      "            ANSWER:  Asian Pacific Islander\n",
      "Category the name enclosed in square brackets into 1 of the following 4 categories: Asian Pacific Islander, Black, Hispanic, or White. \n",
      "            Your answer should only be the category name.\n",
      "            [Johnson Africa]\n",
      "            ANSWER:  Black\n",
      "\n",
      "Please\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test, model, tokenizer)\n",
    "y_pred1 = predict(X_test, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hispanic', 'Black', 'White', 'API'}\n",
      "{'Hispanic', 'API', 'White', 'Black'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hispanic', 'Black', 'White', 'API']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_res = set(y_pred)  # Get unique labels\n",
    "print(unique_res)\n",
    "\n",
    "unique_labels = set(y_true)\n",
    "print(unique_labels)\n",
    "\n",
    "labels = list(set(list(set(y_true))+list(set(y_pred))))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.099\n",
      "Accuracy for label 0: 0.971\n",
      "Accuracy for label 1: 0.013\n",
      "Accuracy for label 2: 0.432\n",
      "Accuracy for label 3: 0.007\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         API       0.02      0.97      0.04       104\n",
      "       Black       0.47      0.01      0.02       706\n",
      "    Hispanic       0.89      0.43      0.58       874\n",
      "       White       0.73      0.01      0.01      3504\n",
      "\n",
      "    accuracy                           0.10      5188\n",
      "   macro avg       0.53      0.36      0.17      5188\n",
      "weighted avg       0.71      0.10      0.11      5188\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 101    0    3    0]\n",
      " [ 689    9    2    6]\n",
      " [ 491    2  378    3]\n",
      " [3431    8   41   24]]\n"
     ]
    }
   ],
   "source": [
    "# y_pred = ['API' if 'Asia Pacific Islander' in x else x for x in y_pred]\n",
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 378    2    3  491]\n",
      " [   2    9    6  689]\n",
      " [  41    8   24 3431]\n",
      " [   3    0    0  101]]\n"
     ]
    }
   ],
   "source": [
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Micro): 0.099\n",
      "F1 Score (Macro): 0.166\n",
      "F1 Score (Weighted): 0.112\n"
     ]
    }
   ],
   "source": [
    "f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f\"F1 Score (Micro): {f1_micro:.3f}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.3f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API API\n",
      "API API\n",
      "API API\n",
      "Hispanic Hispanic\n",
      "API Black\n",
      "API API\n",
      "API API\n",
      "White White\n",
      "API API\n",
      "API API\n",
      "Black Black\n"
     ]
    }
   ],
   "source": [
    "for item1, item2 in zip(y_pred1, y_pred):\n",
    "    print(item1, item2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
